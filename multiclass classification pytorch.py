# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KDhr23XANmtE0XOKgL6EGcAhnKO9FR36
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset

# Define the dataset class
class MulticlassClassificationDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# Define the model
class MulticlassClassificationModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(MulticlassClassificationModel, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        out = self.softmax(out)
        return out

# Define the hyperparameters
input_dim = 10
hidden_dim = 5
output_dim = 3
lr = 0.001
num_epochs = 100

# Create the dataset
X = torch.randn(100, input_dim)
y = torch.randint(low=0, high=output_dim, size=(100, 1)).squeeze()
dataset = MulticlassClassificationDataset(X, y)

# Create the data loader
batch_size = 10
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Create the model and the loss function
model = MulticlassClassificationModel(input_dim, hidden_dim, output_dim)
criterion = nn.CrossEntropyLoss()

# Create the optimizer
optimizer = optim.SGD(model.parameters(), lr=lr)

# Train the model
for epoch in range(num_epochs):
    for batch_X, batch_y in data_loader:
        # Forward pass
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    if (epoch+1) % 10 == 0:
        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))

# Test the model
with torch.no_grad():
    X_test = torch.randn(10, input_dim)
    y_test = torch.randint(low=0, high=output_dim, size=(10, 1)).squeeze()
    outputs = model(X_test)
    _, predicted = torch.max(outputs, dim=1)
    accuracy = (predicted == y_test).float().mean()
    print('Test Accuracy: {:.4f}'.format(accuracy.item()))

